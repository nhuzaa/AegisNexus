#!/usr/bin/env python3
"""
Enhanced Speech Recognition Demo

This demo shows the complete flow of speech recognition with enhanced terminal output:
1. Speech-to-text with prominent terminal display
2. Automatic SRE agent processing
3. Text-to-speech response generation

Run this after starting the server to see the enhanced terminal output in action.
"""

import asyncio
import websockets
import json
import base64
import os
import sys

# Add the parent directory to the path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

class EnhancedSpeechDemo:
    """Demo class showcasing enhanced speech recognition with terminal output"""
    
    def __init__(self):
        self.websocket_url = "ws://localhost:8001/speech-streaming/stream"
        self.websocket = None
    
    async def connect(self):
        """Connect to WebSocket server"""
        try:
            print("ğŸ”— Connecting to WebSocket server...")
            self.websocket = await websockets.connect(self.websocket_url)
            print("âœ… Connected successfully!")
            return True
        except Exception as e:
            print(f"âŒ Connection failed: {str(e)}")
            return False
    
    async def demonstrate_speech_recognition(self, audio_file_path: str):
        """Demonstrate speech recognition with enhanced output"""
        print("\n" + "="*100)
        print("ğŸ¤ SPEECH RECOGNITION DEMONSTRATION")
        print("="*100)
        print("ğŸ¯ WHAT TO WATCH:")
        print("   1. Client side: This terminal will show test progress")
        print("   2. Server side: The server terminal will show ENHANCED OUTPUT including:")
        print("      â€¢ Prominent speech recognition results")
        print("      â€¢ SRE agent processing with clear visual feedback")
        print("      â€¢ Response generation status")
        print("="*100)
        
        if not os.path.exists(audio_file_path):
            print(f"âŒ Audio file not found: {audio_file_path}")
            return
        
        # Read and encode audio
        with open(audio_file_path, "rb") as f:
            audio_data = f.read()
        
        audio_b64 = base64.b64encode(audio_data).decode('utf-8')
        
        message = {
            "type": "audio",
            "data": audio_b64,
            "metadata": {
                "voice_name": "en-US-AriaNeural"
            }
        }
        
        print(f"\nğŸ§ CLIENT: Sending audio file ({len(audio_data)} bytes)")
        print("ğŸ“¡ CLIENT: Audio data transmitted to server...")
        print("ğŸ‘€ CLIENT: Now check the SERVER TERMINAL for enhanced output!")
        print("ğŸ”„ CLIENT: Waiting for responses...")
        
        await self.websocket.send(json.dumps(message))
        
        # Collect responses with client-side feedback
        response_count = 0
        transcribed_text = ""
        
        while response_count < 3:  # Expect 3 responses
            try:
                response = await asyncio.wait_for(self.websocket.recv(), timeout=30)
                response_data = json.loads(response)
                response_count += 1
                
                response_type = response_data.get('type')
                
                if response_type == 'transcription':
                    transcribed_text = response_data.get('data', '')
                    confidence = response_data.get('metadata', {}).get('confidence')
                    print(f"\nğŸ“¥ CLIENT: Received transcription response")
                    print(f"ğŸ¯ CLIENT: Recognized text: '{transcribed_text}'")
                    print(f"ğŸ“Š CLIENT: Confidence: {confidence}")
                    
                elif response_type == 'sre_response':
                    sre_text = response_data.get('data', '')
                    print(f"\nğŸ¤– CLIENT: Received SRE agent response")
                    print(f"ğŸ’¬ CLIENT: Response preview: '{sre_text[:80]}{'...' if len(sre_text) > 80 else ''}'")
                    
                elif response_type == 'response_audio':
                    audio_length = response_data.get('metadata', {}).get('audio_length', 0)
                    voice_name = response_data.get('metadata', {}).get('voice_name', 'unknown')
                    print(f"\nğŸµ CLIENT: Received response audio")
                    print(f"ğŸ”Š CLIENT: Audio length: {audio_length} bytes")
                    print(f"ğŸ™ï¸ CLIENT: Voice: {voice_name}")
                    break
                    
                elif response_type == 'error':
                    error_msg = response_data.get('data', 'Unknown error')
                    print(f"\nâŒ CLIENT: Error received: {error_msg}")
                    break
                    
            except asyncio.TimeoutError:
                print("\nâ° CLIENT: Timeout waiting for response")
                break
            except Exception as e:
                print(f"\nâŒ CLIENT: Error receiving response: {str(e)}")
                break
        
        print("\n" + "="*100)
        print("âœ… DEMONSTRATION COMPLETE!")
        print("="*100)
        print("ğŸ“‹ SUMMARY:")
        print(f"   â€¢ Input audio file: {audio_file_path}")
        print(f"   â€¢ Recognized speech: '{transcribed_text}'")
        print(f"   â€¢ Responses received: {response_count}")
        print("ğŸ’¡ ENHANCED OUTPUT:")
        print("   â€¢ Check the server terminal for detailed visual feedback")
        print("   â€¢ Speech recognition results are prominently displayed")
        print("   â€¢ SRE agent processing is clearly marked")
        print("   â€¢ Each step is visually separated for clarity")
        print("="*100)
    
    async def demonstrate_text_input(self, text: str):
        """Demonstrate text input processing"""
        print("\n" + "="*100)
        print("ğŸ’¬ TEXT INPUT DEMONSTRATION")
        print("="*100)
        print("ğŸ¯ WHAT TO WATCH:")
        print("   â€¢ Server terminal will show enhanced text processing output")
        print("   â€¢ SRE agent processing will be clearly visible")
        print("="*100)
        
        message = {
            "type": "text",
            "data": text,
            "metadata": {
                "with_audio": True,
                "voice_name": "en-US-AriaNeural"
            }
        }
        
        print(f"\nğŸ’¬ CLIENT: Sending text input: '{text}'")
        print("ğŸ‘€ CLIENT: Check the SERVER TERMINAL for enhanced text processing output!")
        
        await self.websocket.send(json.dumps(message))
        
        response_count = 0
        while response_count < 2:  # Expect SRE response and audio
            try:
                response = await asyncio.wait_for(self.websocket.recv(), timeout=20)
                response_data = json.loads(response)
                response_count += 1
                
                response_type = response_data.get('type')
                
                if response_type == 'sre_response':
                    sre_text = response_data.get('data', '')
                    print(f"\nğŸ¤– CLIENT: SRE response received")
                    print(f"ğŸ’¬ CLIENT: Response: '{sre_text[:80]}{'...' if len(sre_text) > 80 else ''}'")
                    
                elif response_type == 'response_audio':
                    audio_length = response_data.get('metadata', {}).get('audio_length', 0)
                    print(f"\nğŸµ CLIENT: Audio response received ({audio_length} bytes)")
                    break
                    
            except asyncio.TimeoutError:
                print("\nâ° CLIENT: Timeout waiting for response")
                break
            except Exception as e:
                print(f"\nâŒ CLIENT: Error: {str(e)}")
                break
        
        print("\nâœ… TEXT INPUT DEMONSTRATION COMPLETE!")
    
    async def disconnect(self):
        """Disconnect from server"""
        if self.websocket:
            await self.websocket.close()
            print("ğŸ”Œ Disconnected from server")

async def run_enhanced_demo():
    """Run the complete enhanced speech recognition demo"""
    print("ğŸš€ ENHANCED SPEECH RECOGNITION DEMO")
    print("="*100)
    print("ğŸ“‹ This demo showcases the enhanced terminal output features:")
    print("   â€¢ Clear visual separation of processing steps")
    print("   â€¢ Prominent display of speech recognition results")
    print("   â€¢ Enhanced SRE agent processing feedback")
    print("   â€¢ Color-coded status indicators")
    print("\nğŸ’¡ IMPORTANT: Keep both terminals visible:")
    print("   â€¢ This terminal: Shows client-side progress")
    print("   â€¢ Server terminal: Shows enhanced server-side output")
    print("="*100)
    
    demo = EnhancedSpeechDemo()
    
    if not await demo.connect():
        print("âŒ Cannot proceed without connection")
        return
    
    try:
        # Demo 1: Speech recognition with audio file
        await demo.demonstrate_speech_recognition("./audio/simplequestion.wav")
        
        # Wait a moment between demos
        print("\nâ³ Pausing between demonstrations...")
        await asyncio.sleep(2)
        
        # Demo 2: Text input processing
        await demo.demonstrate_text_input("Show me the system health status and any current alerts")
        
    finally:
        await demo.disconnect()

def check_prerequisites():
    """Check if all prerequisites are met"""
    print("ğŸ” Checking prerequisites...")
    
    # Check server
    try:
        import requests
        response = requests.get("http://localhost:8001/speech-streaming/health", timeout=3)
        if response.status_code != 200:
            print("âŒ Server health check failed")
            return False
        print("âœ… Server is running")
    except Exception:
        print("âŒ Server is not running on localhost:8001")
        print("ğŸ’¡ Start the server with: uv run uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload")
        return False
    
    # Check audio file
    audio_file = "./audio/simplequestion.wav"
    if not os.path.exists(audio_file):
        print(f"âŒ Audio file not found: {audio_file}")
        print("ğŸ’¡ Please ensure the test audio file exists")
        return False
    print("âœ… Test audio file found")
    
    return True

if __name__ == "__main__":
    print("ğŸ¤ Enhanced Speech Recognition Demo")
    print("="*50)
    
    if not check_prerequisites():
        print("\nâŒ Prerequisites not met. Please resolve the issues above.")
        sys.exit(1)
    
    print("\nğŸš€ Starting enhanced demo...")
    print("ğŸ‘€ Watch both terminals for complete experience!")
    
    asyncio.run(run_enhanced_demo())
